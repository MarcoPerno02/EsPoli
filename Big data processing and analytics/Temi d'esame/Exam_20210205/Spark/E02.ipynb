{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie necessarie\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, DoubleType, TimestampType\n",
    "from pyspark.sql.functions import col, year, sum, to_timestamp, count, expr, max, count_distinct, expr, when, avg, min, month, floor, lag, desc\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# df_updated = df.withColumns({\n",
    "#     \"Country\": when((col(\"Country\") == \"America\") & (col(\"Population\") > 10000), \"North America\").otherwise(col(\"Country\")),\n",
    "#     \"Region\": when((col(\"Country\") == \"America\") & (col(\"Population\") > 10000), \"NA\").otherwise(col(\"Region\"))\n",
    "# })\n",
    "\n",
    "# df_updated = df.withColumn(\n",
    "#     \"Country\",\n",
    "#     when(col(\"Country\") == \"America\", \n",
    "#          when(col(\"Population\") > 10000, \"North America\")\n",
    "#          .when(col(\"Population\") > 5000, \"Central America\")\n",
    "#          .otherwise(\"South America\"))\n",
    "#     .otherwise(col(\"Country\"))\n",
    "# )\n",
    "\n",
    "# df_updated = df.withColumn(\n",
    "#     \"Country\",\n",
    "#     expr(\"CASE WHEN Country = 'America' AND Population > 10000 THEN 'North America' ELSE Country END\")\n",
    "# )\n",
    "\n",
    "# CASE \n",
    "#     WHEN Country = 'America' AND Population > 10000 THEN 'North America' \n",
    "#     WHEN Country = 'America' AND Population > 5000 THEN 'Central America'\n",
    "#     WHEN Country = 'America' THEN 'South America' \n",
    "#     ELSE Country\n",
    "# END\n",
    "\n",
    "# response2 = (\n",
    "#     monthly_water_consumption\n",
    "#     .withColumn(\"Year\", year(col(\"Month\")))\n",
    "#     .groupBy(col(\"HID\"), col(\"Year\"))\n",
    "#     .agg(sum(\"M3\").alias(\"AnnualM3\"))\n",
    "#     .withColumn(\"PreviousAnnualM3\", lag(\"AnnualM3\").over(\n",
    "#         Window\n",
    "#         .partitionBy(\"HID\")\n",
    "#         .orderBy(col(\"Year\"))\n",
    "#     ))\n",
    "#     .filter(col(\"PreviousAnnualM3\") > col(\"AnnualM3\")\n",
    "# )\n",
    "\n",
    "# .withColumn(\n",
    "#     \"HighNumberOfCitiesForCountry\",\n",
    "#     when(col(\"HighNumberOfCitiesForCountry\").isNull(), 0)\n",
    "#     .otherwise(col(\"HighNumberOfCitiesForCountry\"))\n",
    "# )\n",
    "    \n",
    "\n",
    "\n",
    "# Supponiamo che SparkSession sia giÃ  stato creato\n",
    "ss: SparkSession = SparkSession.builder.appName(\"PoliSalesAnalysis\").getOrCreate()\n",
    "\n",
    "# Variabili per i percorsi di input e output\n",
    "# Percorsi dei file di input e output\n",
    "jupyter = False\n",
    "if jupyter:\n",
    "    input_prefix = \"/user/s339450/esami/20240912/\"\n",
    "    output_prefix= \"/user/s339450/esami/20240912/out/\"\n",
    "else:\n",
    "    input_prefix = \".\\\\data\\\\\"\n",
    "    output_prefix= \".\\\\out\\\\\"\n",
    "\n",
    "failures_path = f\"{input_prefix}Failures.txt\"\n",
    "production_plans_path = f\"{input_prefix}ProductionPlans.txt\"\n",
    "robots_path = f\"{input_prefix}Robots.txt\"\n",
    "output_folder_1 = f\"{output_prefix}1/\"\n",
    "output_folder_2 = f\"{output_prefix}2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+-------------------+-------------------+\n",
      "|RID|FailureTypeCode|               Date|               time|\n",
      "+---+---------------+-------------------+-------------------+\n",
      "|R15|       FCode122|2020-05-01 00:00:00|1970-01-01 06:40:51|\n",
      "|R15|       FCode122|2020-05-02 00:00:00|1970-01-01 07:00:00|\n",
      "|R16|       FCode200|2020-06-15 00:00:00|1970-01-01 12:30:25|\n",
      "|R17|       FCode122|2020-07-20 00:00:00|1970-01-01 14:10:10|\n",
      "|R18|       FCode300|2020-08-25 00:00:00|1970-01-01 18:50:05|\n",
      "|R19|       FCode122|2020-09-30 00:00:00|1970-01-01 20:15:30|\n",
      "|R19|       FCode122|2020-09-30 00:00:00|1970-01-01 20:15:30|\n",
      "|R20|       FCode122|2020-09-30 00:00:00|1970-01-01 20:15:30|\n",
      "+---+---------------+-------------------+-------------------+\n",
      "\n",
      "+-------+-------+-------+\n",
      "|PlantID|   City|Country|\n",
      "+-------+-------+-------+\n",
      "|   PID1|  Turin|  Italy|\n",
      "|   PID2| Munich|Germany|\n",
      "|   PID3|Detroit|    USA|\n",
      "|   PID4|  Tokyo|  Japan|\n",
      "|   PID5|  Paris| France|\n",
      "+-------+-------+-------+\n",
      "\n",
      "+---+-------+-------------+\n",
      "|RID|PlantID|           IP|\n",
      "+---+-------+-------------+\n",
      "|R15|   PID1|130.192.20.21|\n",
      "|R16|   PID2|140.110.30.45|\n",
      "|R17|   PID3|150.200.40.50|\n",
      "|R18|   PID4|160.250.50.60|\n",
      "|R19|   PID5|170.300.60.70|\n",
      "|R20|   PID5|170.300.60.70|\n",
      "+---+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "failures_schema = StructType([\n",
    "    StructField(\"RID\", StringType(), False),\n",
    "    StructField(\"FailureTypeCode\", StringType(), False),\n",
    "    StructField(\"Date\", StringType(), False),\n",
    "    StructField(\"Time\", StringType(), False),\n",
    "])\n",
    "\n",
    "failures: DataFrame = ss.read.load(failures_path,\n",
    "    format=\"csv\",\n",
    "    header=False,\n",
    "    schema=failures_schema,\n",
    "    sep=\",\")\n",
    "\n",
    "# Conversione del timestamp\n",
    "failures = failures.withColumn(\n",
    "    \"Date\",\n",
    "    to_timestamp(col(\"Date\"), \"yyyy/MM/dd\")  # Adatta il formato del timestamp\n",
    ")\n",
    "\n",
    "# Conversione del timestamp\n",
    "failures = failures.withColumn(\n",
    "    \"time\",\n",
    "    to_timestamp(col(\"time\"), \"HH:mm:ss\")  # Adatta il formato del timestamp\n",
    ")\n",
    "\n",
    "failures.show()\n",
    "\n",
    "production_plans_schema = StructType([\n",
    "    StructField(\"PlantID\", StringType(), False),\n",
    "    StructField(\"City\", StringType(), False),\n",
    "    StructField(\"Country\", StringType(), False),\n",
    "])\n",
    "\n",
    "production_plans: DataFrame = ss.read.load(production_plans_path,\n",
    "    format=\"csv\",\n",
    "    header=False,\n",
    "    schema=production_plans_schema,\n",
    "    sep=\",\")\n",
    "\n",
    "production_plans.show()\n",
    "\n",
    "robots_schema = StructType([\n",
    "    StructField(\"RID\", StringType(), False),\n",
    "    StructField(\"PlantID\", StringType(), False),\n",
    "    StructField(\"IP\", StringType(), False)\n",
    "])\n",
    "\n",
    "robots: DataFrame = ss.read.load(robots_path,\n",
    "    format=\"csv\",\n",
    "    header=False,\n",
    "    schema=robots_schema,\n",
    "    sep=\",\")\n",
    "\n",
    "robots.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|PlantID|\n",
      "+-------+\n",
      "|   PID1|\n",
      "|   PID5|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response1 = (\n",
    "    failures\n",
    "    .filter(year(col(\"Date\")) == 2020)\n",
    "    .join(robots, \"RID\")\n",
    "    .groupBy(\"RID\", \"PlantID\")\n",
    "    .agg(count(\"*\"))\n",
    "    .filter(col(\"count(1)\") > 1)\n",
    "    .groupBy(\"PlantID\")\n",
    "    .agg({})\n",
    "    .select(\"PlantID\")\n",
    ")\n",
    "\n",
    "response1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|PlantID|NumOfRobots|\n",
      "+-------+-----------+\n",
      "|   PID1|          1|\n",
      "|   PID2|          0|\n",
      "|   PID3|          0|\n",
      "|   PID4|          0|\n",
      "|   PID5|          1|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response2 = (\n",
    "    failures\n",
    "    .filter(year(col(\"Date\")) == 2020)\n",
    "    .join(robots, \"RID\")\n",
    "    .groupBy(\"RID\", \"PlantID\")\n",
    "    .agg(count(\"*\"))\n",
    "    .filter(col(\"count(1)\") > 1)\n",
    "    .groupBy(\"PlantID\")\n",
    "    .agg(count(\"*\"))\n",
    "    .withColumnRenamed(\"count(1)\", \"NumOfRobots\")\n",
    "    .join(\n",
    "        production_plans,\n",
    "        \"PlantID\",\n",
    "        \"right\"\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"NumOfRobots\",\n",
    "        when(col(\"NumOfRobots\").isNull(), 0)\n",
    "        .otherwise(col(\"NumOfRobots\"))\n",
    "    )\n",
    "    .select(\"PlantID\", \"NumOfRobots\")\n",
    ")\n",
    "\n",
    "response2.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
