{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie necessarie\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, DoubleType, TimestampType\n",
    "from pyspark.sql.functions import col, year, sum, to_timestamp, count, expr, max, count_distinct, expr, when, avg, min, month, floor, lag, desc\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# df_updated = df.withColumns({\n",
    "#     \"Country\": when((col(\"Country\") == \"America\") & (col(\"Population\") > 10000), \"North America\").otherwise(col(\"Country\")),\n",
    "#     \"Region\": when((col(\"Country\") == \"America\") & (col(\"Population\") > 10000), \"NA\").otherwise(col(\"Region\"))\n",
    "# })\n",
    "\n",
    "# df_updated = df.withColumn(\n",
    "#     \"Country\",\n",
    "#     when(col(\"Country\") == \"America\", \n",
    "#          when(col(\"Population\") > 10000, \"North America\")\n",
    "#          .when(col(\"Population\") > 5000, \"Central America\")\n",
    "#          .otherwise(\"South America\"))\n",
    "#     .otherwise(col(\"Country\"))\n",
    "# )\n",
    "\n",
    "# df_updated = df.withColumn(\n",
    "#     \"Country\",\n",
    "#     expr(\"CASE WHEN Country = 'America' AND Population > 10000 THEN 'North America' ELSE Country END\")\n",
    "# )\n",
    "\n",
    "# CASE \n",
    "#     WHEN Country = 'America' AND Population > 10000 THEN 'North America' \n",
    "#     WHEN Country = 'America' AND Population > 5000 THEN 'Central America'\n",
    "#     WHEN Country = 'America' THEN 'South America' \n",
    "#     ELSE Country\n",
    "# END\n",
    "\n",
    "# response2 = (\n",
    "#     monthly_water_consumption\n",
    "#     .withColumn(\"Year\", year(col(\"Month\")))\n",
    "#     .groupBy(col(\"HID\"), col(\"Year\"))\n",
    "#     .agg(sum(\"M3\").alias(\"AnnualM3\"))\n",
    "#     .withColumn(\"PreviousAnnualM3\", lag(\"AnnualM3\").over(\n",
    "#         Window\n",
    "#         .partitionBy(\"HID\")\n",
    "#         .orderBy(col(\"Year\"))\n",
    "#     ))\n",
    "#     .filter(col(\"PreviousAnnualM3\") > col(\"AnnualM3\")\n",
    "# )\n",
    "\n",
    "# .withColumn(\n",
    "#     \"HighNumberOfCitiesForCountry\",\n",
    "#     when(col(\"HighNumberOfCitiesForCountry\").isNull(), 0)\n",
    "#     .otherwise(col(\"HighNumberOfCitiesForCountry\"))\n",
    "# )\n",
    "    \n",
    "\n",
    "\n",
    "# Supponiamo che SparkSession sia giÃ  stato creato\n",
    "ss: SparkSession = SparkSession.builder.appName(\"PoliSalesAnalysis\").getOrCreate()\n",
    "\n",
    "# Variabili per i percorsi di input e output\n",
    "# Percorsi dei file di input e output\n",
    "jupyter = False\n",
    "if jupyter:\n",
    "    input_prefix = \"/user/s339450/esami/20240912/\"\n",
    "    output_prefix= \"/user/s339450/esami/20240912/out/\"\n",
    "else:\n",
    "    input_prefix = \".\\\\data\\\\\"\n",
    "    output_prefix= \".\\\\out\\\\\"\n",
    "\n",
    "companies_path = f\"{input_prefix}Companies.txt\"\n",
    "daily_power_consumption_path = f\"{input_prefix}DailyPowerConsumption.txt\"\n",
    "data_centers_path = f\"{input_prefix}DataCenters.txt\"\n",
    "output_folder_1 = f\"{output_prefix}1/\"\n",
    "output_folder_2 = f\"{output_prefix}2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+--------------------+\n",
      "|CodC|CompanyName|Headquarters-Country|\n",
      "+----+-----------+--------------------+\n",
      "| C12| Databricks|United States of ...|\n",
      "| C13|     Google|United States of ...|\n",
      "| C14|  Microsoft|United States of ...|\n",
      "| C15|     Amazon|United States of ...|\n",
      "| C16|    Alibaba|               China|\n",
      "| C17|   Facebook|United States of ...|\n",
      "| C18|    Twitter|United States of ...|\n",
      "| C19|      Apple|United States of ...|\n",
      "| C20|     Oracle|United States of ...|\n",
      "| C21|        IBM|United States of ...|\n",
      "+----+-----------+--------------------+\n",
      "\n",
      "+-----+----+-------------+-------+-------------+\n",
      "|CodDC|CodC|         City|Country|    Continent|\n",
      "+-----+----+-------------+-------+-------------+\n",
      "| DC21| C12|         Nice| France|       Europe|\n",
      "| DC22| C13|Mountain View|    USA|North America|\n",
      "| DC23| C14|      Redmond|    USA|North America|\n",
      "| DC24| C15|      Seattle|    USA|North America|\n",
      "| DC25| C16|     Hangzhou|  China|         Asia|\n",
      "| DC26| C17|   Menlo Park|    USA|North America|\n",
      "| DC27| C18|San Francisco|    USA|North America|\n",
      "| DC28| C19|    Cupertino|    USA|North America|\n",
      "| DC29| C20| Redwood City|    USA|North America|\n",
      "| DC30| C21|       Armonk|    USA|North America|\n",
      "+-----+----+-------------+-------+-------------+\n",
      "\n",
      "+-----+-------------------+----+\n",
      "|CodDC|               Date| kWh|\n",
      "+-----+-------------------+----+\n",
      "| DC21|2020-01-12 00:00:00| 900|\n",
      "| DC21|2020-01-13 00:00:00|1100|\n",
      "| DC21|2021-01-12 00:00:00|1300|\n",
      "| DC21|2021-01-15 00:00:00|1500|\n",
      "| DC22|2020-01-12 00:00:00| 950|\n",
      "| DC22|2020-01-13 00:00:00|1200|\n",
      "| DC22|2021-01-12 00:00:00|1100|\n",
      "| DC22|2021-01-15 00:00:00|1300|\n",
      "| DC23|2020-01-12 00:00:00| 800|\n",
      "| DC23|2020-01-13 00:00:00|1200|\n",
      "| DC23|2021-01-12 00:00:00|1500|\n",
      "| DC23|2021-01-15 00:00:00|1600|\n",
      "| DC24|2020-01-12 00:00:00|1200|\n",
      "| DC24|2020-01-13 00:00:00|1400|\n",
      "| DC24|2021-01-12 00:00:00|1700|\n",
      "| DC24|2021-01-15 00:00:00|1900|\n",
      "| DC25|2020-01-12 00:00:00| 700|\n",
      "| DC25|2020-01-13 00:00:00| 800|\n",
      "| DC25|2021-01-12 00:00:00| 900|\n",
      "| DC25|2021-01-15 00:00:00|1000|\n",
      "+-----+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "companies_schema = StructType([\n",
    "    StructField(\"CodC\", StringType(), False),\n",
    "    StructField(\"CompanyName\", StringType(), False),\n",
    "    StructField(\"Headquarters-Country\", StringType(), False)\n",
    "])\n",
    "\n",
    "companies: DataFrame = ss.read.load(companies_path,\n",
    "    format=\"csv\",\n",
    "    header=False,\n",
    "    schema=companies_schema,\n",
    "    sep=\",\")\n",
    "\n",
    "companies.show()\n",
    "\n",
    "data_centers_schema = StructType([\n",
    "    StructField(\"CodDC\", StringType(), False),\n",
    "    StructField(\"CodC\", StringType(), False),\n",
    "    StructField(\"City\", StringType(), False),\n",
    "    StructField(\"Country\", StringType(), False),\n",
    "    StructField(\"Continent\", StringType(), False)\n",
    "])\n",
    "\n",
    "data_centers: DataFrame = ss.read.load(data_centers_path,\n",
    "    format=\"csv\",\n",
    "    header=False,\n",
    "    schema=data_centers_schema,\n",
    "    sep=\",\")\n",
    "\n",
    "data_centers.show()\n",
    "\n",
    "daily_power_consumption_schema = StructType([\n",
    "    StructField(\"CodDC\", StringType(), False),\n",
    "    StructField(\"Date\", StringType(), False),\n",
    "    StructField(\"kWh\", IntegerType(), False)\n",
    "])\n",
    "\n",
    "daily_power_consumption: DataFrame = ss.read.load(daily_power_consumption_path,\n",
    "    format=\"csv\",\n",
    "    header=False,\n",
    "    schema=daily_power_consumption_schema,\n",
    "    sep=\",\")\n",
    "\n",
    "# Conversione del timestamp\n",
    "daily_power_consumption = daily_power_consumption.withColumn(\n",
    "    \"Date\",\n",
    "    to_timestamp(col(\"Date\"), \"yyyy/MM/dd\")  # Adatta il formato del timestamp\n",
    ")\n",
    "\n",
    "daily_power_consumption.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               Date|\n",
      "+-------------------+\n",
      "|2021-01-12 00:00:00|\n",
      "|2020-01-13 00:00:00|\n",
      "|2021-01-15 00:00:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response1 = (\n",
    "    daily_power_consumption\n",
    "    .groupBy(\"Date\")\n",
    "    .agg(count(\"*\"))\n",
    "    .withColumnRenamed(\"count(1)\", \"TotNumDC\")\n",
    ")\n",
    "\n",
    "response2 = (\n",
    "    daily_power_consumption\n",
    "    .filter(\"kWh > 1000\")\n",
    "    .groupBy(\"Date\")\n",
    "    .agg(count(\"*\"))\n",
    "    .withColumnRenamed(\"count(1)\", \"NumDC\")\n",
    ")\n",
    "\n",
    "response3 = (\n",
    "    response2\n",
    "    .join(\n",
    "        response1,\n",
    "        \"Date\"\n",
    "    )\n",
    "    .filter(\n",
    "        col(\"NumDc\") / col(\"TotNumDc\") >= 0.8\n",
    "    )\n",
    "    .select(\"Date\")\n",
    ")\n",
    "\n",
    "response3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Big data processing and analytics\\.venv\\Lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Big data processing and analytics\\.venv\\Lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 34\u001b[0m\n\u001b[0;32m     16\u001b[0m response2 \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     17\u001b[0m     data_centers\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContinent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m df_final: DataFrame \u001b[38;5;241m=\u001b[39m ss\u001b[38;5;241m.\u001b[39mcreateDataFrame([\n\u001b[0;32m     30\u001b[0m     response1,\n\u001b[0;32m     31\u001b[0m     response2\n\u001b[0;32m     32\u001b[0m ])\n\u001b[1;32m---> 34\u001b[0m \u001b[43mdf_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistinct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Big data processing and analytics\\.venv\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Big data processing and analytics\\.venv\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Big data processing and analytics\\.venv\\Lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[1;32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Big data processing and analytics\\.venv\\Lib\\site-packages\\py4j\\java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[1;32mc:\\Users\\marco\\Desktop\\Marco\\Programmazione\\C\\EsPoli\\Big data processing and analytics\\.venv\\Lib\\site-packages\\py4j\\clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response1 = (\n",
    "    daily_power_consumption\n",
    "    .filter(year(col(\"Date\")) == 2021)\n",
    "    .join(data_centers, \"CodDC\")\n",
    "    .groupBy(\"Continent\")\n",
    "    .agg(sum(col(\"kWh\")), count_distinct(col(\"CodDC\")))\n",
    "    .withColumn(\n",
    "        \"AvgKWh\",\n",
    "        col(\"sum(kWh)\") / col(\"count(DISTINCT CodDC)\")\n",
    "    )\n",
    "    .sort(desc(\"AvgKWh\"))\n",
    "    .select(\"Continent\")\n",
    "    .head()\n",
    ")\n",
    "\n",
    "response2 = (\n",
    "    data_centers\n",
    "    .groupBy(\"Continent\")\n",
    "    .agg(count(\"*\"))\n",
    "    .withColumnRenamed(\n",
    "        \"count(1)\",\n",
    "        \"NumOfDCs\"\n",
    "    )\n",
    "    .sort(desc(\"NumOfDCs\"))\n",
    "    .select(\"Continent\")\n",
    "    .head()\n",
    ")\n",
    "\n",
    "df_final: DataFrame = ss.createDataFrame([\n",
    "    response1,\n",
    "    response2\n",
    "])\n",
    "\n",
    "df_final.distinct().show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
